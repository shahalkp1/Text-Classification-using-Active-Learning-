{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing dataset\n",
    "import pandas as pd\n",
    "df= pd.read_csv(r\"C:\\Users\\shaha\\Desktop\\IBS\\train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-d574088bc6ff>:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['new_tweet'] = df['new_tweet'].str.replace(\"[^a-zA-Z#]\", \" \" )\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>new_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[dysfunct, drag, selfish, father, kid, run]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[disapoint, lyft, caus, getthank, van, use, pd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[model, time, love, ur, take, u]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[factsguid, motiv, societi]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                          new_tweet\n",
       "0      0        [dysfunct, drag, selfish, father, kid, run]\n",
       "1      0  [disapoint, lyft, caus, getthank, van, use, pd...\n",
       "2      0                                  [bihday, majesti]\n",
       "3      0                   [model, time, love, ur, take, u]\n",
       "4      0                        [factsguid, motiv, societi]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocessing \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "df['new_tweet'] = df.tweet.str.replace('@user', '')\n",
    "df['new_tweet'] = df['new_tweet'].str.replace(\"[^a-zA-Z#]\", \" \" )\n",
    "df['new_tweet'] = df['new_tweet'].str.replace(\"#\", \" \")\n",
    "df['new_tweet'] = df['new_tweet'].apply(lambda x: x.split())\n",
    "df['new_tweet']= df['new_tweet'].apply(lambda x: [stemmer.stem(i) for i in x])\n",
    "def process(text):\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = set(char for char in list(text) if char not in string.punctuation)\n",
    "    # Join the characters to form the string.\n",
    "    nopunc = \" \".join(nopunc)\n",
    "    # remove any stopwords if present\n",
    "    return [word for word in nopunc.lower().split() if word.lower() not in stopwords]\n",
    "df['new_tweet'] = df['new_tweet'].apply(process)\n",
    "df=df.drop(columns='tweet')\n",
    "df=df.drop(columns='id')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer,TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "x_train, x_test, y_train, y_test =train_test_split(df[\"new_tweet\"], df[\"label\"], test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "split=np.array_split(x_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=np.array_split(y_train,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "from typing import Union, List, Sequence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "def multi_argmax(values: np.ndarray, n_instances: int = 50) -> np.ndarray:\n",
    "    assert n_instances <= values.shape[0], 'n_instances must be less or equal than the size of utility'\n",
    "    max_idx = np.argpartition(-values, n_instances-1, axis=0)[:n_instances]\n",
    "    return max_idx\n",
    "\n",
    "def shuffled_argmax(values: np.ndarray, n_instances: int = 50) -> np.ndarray:\n",
    "\n",
    "    assert n_instances <= values.shape[0], 'n_instances must be less or equal than the size of utility'\n",
    "\n",
    "    # shuffling indices and corresponding values\n",
    "    shuffled_idx = np.random.permutation(len(values))\n",
    "    shuffled_values = values[shuffled_idx]\n",
    "\n",
    "    # getting the n_instances best instance\n",
    "    # since mergesort is used, the shuffled order is preserved\n",
    "    sorted_query_idx = np.argsort(shuffled_values, kind='mergesort')[len(shuffled_values)-n_instances:]\n",
    "\n",
    "    # inverting the shuffle\n",
    "    query_idx = shuffled_idx[sorted_query_idx]\n",
    "    return query_idx\n",
    "\n",
    "\n",
    "modALinput = Union[sp.csr_matrix, pd.DataFrame, np.ndarray, list]\n",
    "\n",
    "\n",
    "def data_vstack(blocks: Sequence[modALinput]) -> modALinput:\n",
    "    if any([sp.issparse(b) for b in blocks]):\n",
    "        return sp.vstack(blocks)\n",
    "    elif isinstance(blocks[0], pd.DataFrame):\n",
    "        return blocks[0].append(blocks[1:])\n",
    "    elif isinstance(blocks[0], np.ndarray):\n",
    "        return np.concatenate(blocks)\n",
    "    elif isinstance(blocks[0], list):\n",
    "        return np.concatenate(blocks).tolist()\n",
    "\n",
    "    raise TypeError('%s datatype is not supported' % type(blocks[0]))\n",
    "\n",
    "\n",
    "def retrieve_rows(X: modALinput,I: Union[int, List[int], np.ndarray]) -> Union[sp.csc_matrix, np.ndarray, pd.DataFrame]:\n",
    "    if sp.issparse(X):\n",
    "        try:\n",
    "            return X[I]\n",
    "        except:\n",
    "            sp_format = X.getformat()\n",
    "            return X.tocsr()[I].asformat(sp_format)\n",
    "    elif isinstance(X, pd.DataFrame):\n",
    "        return X.iloc[I]\n",
    "    elif isinstance(X, np.ndarray):\n",
    "        return X[I]\n",
    "    elif isinstance(X, list):\n",
    "        return np.array(X)[I].tolist()\n",
    "\n",
    "    raise TypeError('%s datatype is not supported' % type(X))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classifier_entropy(classifier: BaseEstimator, X: modALinput, **predict_proba_kwargs) -> np.ndarray:\n",
    "    try:\n",
    "        classwise_uncertainty = classifier.predict_proba(X, **predict_proba_kwargs)\n",
    "    except NotFittedError:\n",
    "        return np.zeros(shape=(X.shape[0], ))\n",
    "\n",
    "    return np.transpose(entropy(np.transpose(classwise_uncertainty)))\n",
    "\n",
    "def entropy_sampling(classifier: BaseEstimator, X: modALinput,\n",
    "                     n_instances: int = 50, random_tie_break: bool = False,\n",
    "                     **uncertainty_measure_kwargs) -> np.ndarray:\n",
    "    entropy = classifier_entropy(classifier, X, **uncertainty_measure_kwargs)\n",
    "    if not random_tie_break:\n",
    "        return multi_argmax(entropy, n_instances=n_instances)\n",
    "        \n",
    "    return shuffled_argmax(entropy, n_instances=n_instances)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import sys\n",
    "import warnings\n",
    "from typing import Union, Callable, Optional, Tuple, List, Iterator, Any\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils import check_X_y\n",
    "\n",
    "import scipy.sparse as sp\n",
    "\n",
    "\n",
    "if sys.version_info >= (3, 4):\n",
    "    ABC = abc.ABC\n",
    "else:\n",
    "    ABC = abc.ABCMeta('ABC', (), {})\n",
    "\n",
    "\n",
    "class ActiveLearner(ABC, BaseEstimator):\n",
    "\n",
    "    def __init__(self,\n",
    "                 estimator: BaseEstimator,\n",
    "                 query_strategy: Callable,\n",
    "                 X_training: Optional[modALinput] = None,\n",
    "                 y_training: Optional[modALinput] = None,\n",
    "                 bootstrap_init: bool = False,\n",
    "                 on_transformed: bool = False,\n",
    "                 force_all_finite: bool = True,\n",
    "                 **fit_kwargs\n",
    "                 ) -> None:\n",
    "        assert callable(query_strategy), 'query_strategy must be callable'\n",
    "\n",
    "        self.estimator = estimator\n",
    "        self.query_strategy = query_strategy\n",
    "        self.on_transformed = on_transformed\n",
    "\n",
    "        self.X_training = X_training\n",
    "        self.y_training = y_training\n",
    "        if X_training is not None:\n",
    "            self._fit_to_known(bootstrap=bootstrap_init, **fit_kwargs)\n",
    "\n",
    "        assert isinstance(force_all_finite, bool), 'force_all_finite must be a bool'\n",
    "        self.force_all_finite = force_all_finite\n",
    "\n",
    "    def _add_training_data(self, X: modALinput, y: modALinput) -> None:\n",
    "        check_X_y(X, y, accept_sparse=True, ensure_2d=False, allow_nd=True, multi_output=True, dtype=None,\n",
    "                  force_all_finite=self.force_all_finite)\n",
    "\n",
    "        if self.X_training is None:\n",
    "            self.X_training = X\n",
    "            self.y_training = y\n",
    "        else:\n",
    "            try:\n",
    "                self.X_training = data_vstack((self.X_training, X))\n",
    "                self.y_training = data_vstack((self.y_training, y))\n",
    "            except ValueError:\n",
    "                raise ValueError('the dimensions of the new training data and label must'\n",
    "                                 'agree with the training data and labels provided so far')\n",
    "\n",
    "    def _fit_to_known(self, bootstrap: bool = False, **fit_kwargs) -> 'BaseLearner':\n",
    "        if not bootstrap:\n",
    "            self.estimator.fit(self.X_training, self.y_training, **fit_kwargs)\n",
    "        else:\n",
    "            n_instances = self.X_training.shape[0]\n",
    "            bootstrap_idx = np.random.choice(range(n_instances), n_instances, replace=True)\n",
    "            self.estimator.fit(self.X_training[bootstrap_idx], self.y_training[bootstrap_idx], **fit_kwargs)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: modALinput, **predict_kwargs) -> Any:\n",
    "        return self.estimator.predict(X, **predict_kwargs)\n",
    "\n",
    "    def predict_proba(self, X: modALinput, **predict_proba_kwargs) -> Any:\n",
    "        return self.estimator.predict_proba(X, **predict_proba_kwargs)\n",
    "\n",
    "    def query(self, X_pool, *query_args, **query_kwargs) -> Union[Tuple, modALinput]:\n",
    "        query_result = self.query_strategy(self, X_pool, *query_args, **query_kwargs)\n",
    "\n",
    "        return query_result, retrieve_rows(X_pool, query_result)\n",
    "    \n",
    "    def teach(self, X: modALinput, y: modALinput, bootstrap: bool = False, only_new: bool = False, **fit_kwargs) -> None:\n",
    "\n",
    "        self._add_training_data(X, y)\n",
    "        if not only_new:\n",
    "            self._fit_to_known(bootstrap=bootstrap, **fit_kwargs)\n",
    "        else:\n",
    "            self._fit_on_new(X, y, bootstrap=bootstrap, **fit_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words='english')\n",
    "transformer = TfidfTransformer(norm='l2',sublinear_tf=True)\n",
    "x_train_counts = count_vect.fit_transform(split[0].apply(lambda x: ' '.join(x)))\n",
    "x_train_tfidf = transformer.fit_transform(x_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.10292507430002\n"
     ]
    }
   ],
   "source": [
    "\n",
    "learner = ActiveLearner(estimator=RandomForestClassifier(),query_strategy=entropy_sampling,X_training=x_train_tfidf, y_training=label[0].ravel())\n",
    "x_test_counts = count_vect.transform(x_test.apply(lambda x: ' '.join(x)))\n",
    "x_test_tfidf = transformer.transform(x_test_counts)\n",
    "predictions = learner.predict(x_test_tfidf)\n",
    "print(accuracy_score(y_test,predictions)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.19787267323635\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    x_counts = count_vect.transform(split[i].apply(lambda x: ' '.join(x)))\n",
    "    x_tfidf = transformer.transform(x_counts)\n",
    "    query_idx, query_sample = learner.query(x_tfidf)\n",
    "      #print(query_idx)\n",
    "      #print(query_sample)\n",
    "    split[i]=split[i].reset_index()\n",
    "    split[i]=split[i].copy()\n",
    "    split[i]=split[i].drop(['index'],axis=1)\n",
    "    y=[]\n",
    "      #print(split[i].loc[query_idx])\n",
    "    for k in query_idx:\n",
    "      j=label[i].iloc[k]\n",
    "      #print(x_tfidf[query_idx])\n",
    "      lb=j.item()\n",
    "      y.append(lb)\n",
    "      #inp=int(input(\"Enter the label\"))\n",
    "    learner.teach(x_tfidf[query_idx],y)\n",
    "x_test_counts = count_vect.transform(x_test.apply(lambda x: ' '.join(x)))\n",
    "x_test_tfidf = transformer.transform(x_test_counts)\n",
    "predictions = learner.predict(x_test_tfidf)\n",
    "print(accuracy_score(y_test,predictions)*100)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
